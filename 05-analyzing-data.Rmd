---
output:
  pdf_document: default
  html_document: default
---


# Analyzing the Data {#analyzing}

## Basic steps when analyzing the data

Think again about your research question and what you are trying to learn or discover. How can you use your data to answer this question?

The data to be analyzed should correspond to the core elements of the hypothesis to be investigated. You investigate whether the postulated cause-effect relationship exists, or quantitatively identify the strength of the effect. To perform a reproducible research project, you will need to create a set of programs that describes how the secondary data used was synthesized, process and analysed. To document all steps of your analysis, you should use programs like Stata or R.

Across all steps, try to use data visualization using tables and diagrams. These are an essential part of your work and not an accessory. Visualizations help to support the argumentation in the text and visualize complex facts in a simple form. In the following, we describe the three major tasks for data analysis

1. Generate the analysis data set
2. Describe your data, assess validity and plausiblity
3. Generate estimates of your investigated effect using regression techniques

<!--[Example of visualized vs. non-visualized data]-->

### Generate the analysis data set

There are three major tasks that are typically needed to generate the analysis data set:

**1. Clean your data.**

  - get/collect the data and transfer them in a format you use, for example to .dta from .xlsx (if neccessary)
  - Make sure that you link different data sets correctly using correct identifiers.
  - Take time to look through the data, check them, and delete anything that looks suspicious. 
  - Select your sample of interest.
  - Generate and leave only variables necessary for your anaylsis.
  - Ensure that you make plausible and relevant exclusion decisions, for example regarding the time period studied, products, health conditions, age groups.
  
  
**2. Structuring and aggregating of the analysis data**


  - Only include variables of your empirical model to be included to the analysis data set!
  - Aggregate your data to the level of analysis. For example, if you aim to analyse physician behavior over time, there should be one observation for each time period and physician (panel data). If your data is purely cross-sectional, there should not be multiple time periods in your data. That means in a cross-section of physicians, one row represents one physician.


**4. Store your data**

  - Your analysis data set is the most important piece for your analyis.
  - Physically store the version of your analysis data set that you are using.
  - Use version control if you are modifying your analysis data set.
  - Ensure that the code to create your analysis data set is complete and can reproduce the analysis data set completely.


### Describe your data, assess validity and plausiblity

Start the data analysis by doing some descriptive analyses of your data and sample. Once you have selected the necessary variables, generated new variables for the analysis, and combined all the necessary datasets into one analysis dataset you can start your empirical investigation. 

  - Check the plausibility by looking at basic descriptives (N, mean, median, frequencies)
  - Plot the distribution of your data using histograms, boxplots, bar charts
  - Critically reflect any anormalities: Compare your data with the reference literature
  - Are descriptives similar? If not, why so? Try to assess coding problems, different population, unbalanced samples.

### Generate estimates of your investigated effect using regression techniques

- Once you have decided on the type of empirical analyses you would like to perform, run the regressions.
- Perform the regression analyses, that means by using the appropriate procedure to estimate regressions that reflect your empirical strategy.
- Create output tables that report your results which outsiders can understand, for example label your variables properly
- Concentrate on analyzing and interpreting the effects of your variable of interest ($X$)
  - interpret and show in tables ony most important and relevant coefficients related to the research question. For example, you do not need to interpret and display coefficients for all of the incuded control variables, just the main variables of interest. 
- Think about how to interpret your estimates.
- Challenge your approach. Investigate why your estimates could not be plausible?
- Again, compare with existing literature.


- What does your data say? After you run the regressions, look at the results:

    - Are your main coefficients of interest statistically significant, that means is the p-value smaller than 0.05 or any other pre-defined level of significance?
    - Consider also the economic significance of your results. Is the effect you are measuring large or small? 
    - Do your results make sense or are they counterintuitive? This might give you a clue that you might have misspecified your regression or made a mistake in your analysis.


## Resources box

**Data Analysis**


- [Princeton University Library: Getting Started in Data Analysis using Stata and R](https://dss.princeton.edu/training/)
- [Data Analysis for Business, Economics, and Policy](https://gabors-data-analysis.com/)


**Organizing your workflow, programming and automation**

- [Gentzkow M, Shapiro J. Code and Data for the Social Sciences: A Practitionerâ€™s Guide [Internet]. Chicago Booth and NBER; 2014]( https://web.stanford.edu/~gentzkow/research/CodeAndData.pdf)
- [The Stata workflow Guide](https://medium.com/the-stata-guide/the-stata-workflow-guide-52418ce35006)
- [In Stata coding, Style is the Essential: A brief commentary on do-file style](https://michaelshill.net/2015/07/31/in-stata-coding-style-is-the-essential/)



**Data Visualization**

- The chapter [Data Visualization Basics by Hans Sievertsen](https://hhsievertsen.github.io/EconDataBook/data-visualization-basics.html) includes important resources for the fundamentals of data visualization
- [Stata Cheat Sheet on Visualization](https://www.stata.com/bookstore/stata-cheat-sheets/) provides an overview of the technical implementation
- [Jones AM. Data visualization and health econometrics. Foundations and Trends in Econometrics. 2017](https://doi.org/10.1561/0800000033)

**Create journal submission ready output tables**

- [Creating Publication-Quality Tables in Stata](https://ssc.wisc.edu/sscc/pubs/stata_tables.htm)
- [Stata commands to plot regression coefficients, make regression tables and visualize results by Ben Jann](http://repec.sowi.unibe.ch/stata/)



<!--References:

- Fresno State Graduate Writing Studio. [A Statistical Checklist for Your Spring Thesis](https://fresnostategraduatewritingstudio.wordpress.com/)

- https://blog.feedspot.com/data_visualization_blogs/-->


## Example: Hellerstein (1998)

Hellerstein's (1998) study aims to answer the research question if physicians vary their prescription decisions on a patient-by-patient basis or whether they systematically prescribe the same version of a drug, trade-name or generic, to all patients.

<!-- That is not in line with Chapters 2 and 3 that emphasizes the effect of the insurance status -->

This means that secondary data (NAMCS and NAMCSd) that is publicly available via the websites of the CDC will be analysed on physician level in a cross-sectional format. Thus, the primary interest is to investigate if the physicians do or do not prescribe a generic drug. We are not investigating prescription behaviour of physicians over time using panel data.
Over the course of your analysis, you want to explore your dataset, this includes describing and assessing the validity and plausibility. Thus before generating estimates of your investigated effect using regression techniques, you want to describe your data using descriptive statistics presented in tables and figures.

<!-- The language and how the reader is addressed is changing throughout the text. At times, you talk about, what we have done and then what the reader should do -- adjust.-->

We first reproduce the descriptive statistics of Hellerstein (1998), namely table 1-3 and figure 1-2. Details of created variables can be found in the data preparation .do-file and the notes of the tables and figures in Hellerstein's (1998) paper.

<!-- Table that describes the dataset-->

Please keep in mind that we used the data of 1991. Thus, our numbers are not matching with the numbers provided in the original paper. 

We explain the steps taken to reproduce table 1-3 and figure 1-2, and the reproduction of the empirical analyses. Details and the code can be found in the Appendix<!--[include reference / link, recommend to split the code into the separate tables and figures and show below]--> and at the end of the next chapter when reporting the study results.

### Describe your data, assess validity and plausiblity

**Table 1:**

Compute the mean and summary statistics for the age and the previously established dummies in the NAMCS data.

**Table 2:**

For the first two columns, repeat the procedure of table 1 using the NAMCSd data. For the third column, compute the mean of the generic indicator for all subpopulations defined by the dummies.

**Table 3:**

Using summary statistics command, count the number of observations for the full sample and for each of the eight defined drug classes. Further, compute the mean of the generic indicator in the full sample and each drug class subsample. 

**Figure 1:**

For each physician, compute the mean of the generic indicator and drop duplicate observations per physician. This way, every physician has a unique observation with a respective share of generic prescriptions. To approximate the distribution shown in figure 1, we chose the following specifications based on visual approximation like:

  - The decimal places at which the average generic share was rounded: $.01$
  - The bandwidth: $0.02$
  - The kernel function: bilinear form

**Figure 2:**

To display Figure 2, keep physicians that prescribe the same multisource drug to at least six patients, independent of whether it is in its generic or trade-name form. Compute the mean of the generic share for each remaining physician and create a categorical<!--dummy variable often implies 2 categories--> variable on whether this mean is zero (only trade name drugs), one (only generic drugs), or something in between (both, that means a mix of generic and brand name versions). The frequencies of these three categories across physicians is then plotted in a bar plot. 

### Generate estimates of your investigated effect using regression techniques

Hellerstein applies a random effects probit regression model aggregated on physician level. The parameterization of the model is implemented as follows:

**Dependent variable $Y$**

  - $G$: *Generic compared to brand name drug use*
  
*Note that Hellerstein uses a somewhat different notation for the outcome variable which is denoted as $G$. Today, it is often common to denote this variably by $Y$.*
	
**Variable of interest or treatment $X$**	<!--what about insurance status? That should be X if we follow section 3, we somehow need to align this with chapter 3-->

  - $P$:	*Insurance status by: Medicare, Medicaid, HMO/prepaid, private insurance, self-paid (this is the omitted category)*
  
*Note that Hellerstein uses a somewhat different notation for the variable of interest which is denoted as $P$. Today, it is often common to denote this variably by $X$ or $D$.*

**Confounders $Z$ of the effect of insurance status $X$ and generic compared to brand name drug use $Y$.**

  - $C$: 	*Drug class identifiers among 8 classes (Pain relief omitted, see footnote table 5)*
  - $X$:	*Patient characteristics: age, sex, race*
  - $S$:	*Physician specialist status: Specialist, general practicioner (omitted)*
  - $R$:	*Region as classified by: Midwest, South, West, Northeast (omitted)*
  - vector $X$, vector $P$:	*Averages <!-Of WHAT?--> across physician*
  
*Note that Hellerstein uses a somewhat different notation for confounding variables. It is often common to denote the variable of interest using the index $X$, but not necessarily confounders.*

**Table 4 and 5:**

Estimate the regression coefficients, t-statistics and marginal effects of the regression model. It is not specified whether the model for both tables contain all covariates specified in equation 10 or just the variables mentioned in the tables. We decided to use the full model for both tables. Marginal effects are the average marginal effects (AME) across individuals (footnote table 4).

**Table 6:**

Run a separate regression using only observations of a single drug class and report the coefficients of the payment dummies and their average marginal effects (AMEs).


Tables 7, 8 and 9 cannot be reproduced. The publicly available data of NACMS does not provide a variable to identify physicians and patients by region.

