---
output:
  pdf_document: default
  html_document: default
---


# Analyzing the Data {#analyzing}

## Basic steps when analyzing the data

Think again about your research question and what you are trying to learn or discover. How can you use your data to answer this question?

The data to be analyzed should correspond to the core elements of the hypothesis to be investigated. You investigate whether the postulated cause-effect relationship exists, or quantitatively identify the strength of the effect. To perform a reproducible research project, you will need to create a set of programs that describes how the secondary data used was synthesized, process and analysed. To document all steps of your analysis, you should use programs like Stata or R.

Across all steps, try to use data visualization using tables and diagrams. These are an essential part of your work and not an accessory. Visualizations help to support the argumentation in the text and visualize complex facts in a simple form. In the following, we describe the three major tasks for data analysis

1. Generate the analysis data set
2. Describe your data, assess validity and plausiblity
3. Generate estimates of your investigated effect using regression techniques

<!--[Example of visualized vs. non-visualized data]-->

### Generate the analysis data set

There are three major tasks that are typically needed to generate the analysis data set:

**1. Clean your data.**

  - get/collect the data and transfer them in a format you use, for example to .dta from .xlsx (if neccessary)
  - Make sure that you link different data sets correctly using correct identifiers.
  - Take time to look through the data, check them, and delete anything that looks suspicious. 
  - Select your sample of interest.
  - Generate and leave only variables necessary for your anaylsis.
  - Ensure that you make plausible and relevant exclusion decisions, for example regarding the time period studied, products, health conditions, age groups.
  
  
**2. Structuring and aggregating of the analysis data**


  - Only include variables of your empirical model to be included to the analysis data set!
  - Aggregate your data to the level of analysis. For example, if you aim to analyse physician behavior over time, there should be one observation for each time period and physician (panel data). If your data is purely cross-sectional, there should not be multiple time periods in your data. That means in a cross-section of physicians, one row represents one physician.


**4. Store your data**

  - Your analysis data set is the most important piece for your analyis.
  - Physically store the version of your analysis data set that you are using.
  - Use version control if you are modifying your analysis data set.
  - Ensure that the code to create your analysis data set is complete and can reproduce the analysis data set completely.


### Describe your data, assess validity and plausiblity

Start the data analysis by doing some descriptive analyses of your data and sample. Once you have selected the necessary variables, generated new variables for the analysis, and combined all the necessary datasets into one analysis dataset you can start your empirical investigation. 

  - Check the plausibility by looking at basic descriptives (N, mean, median, frequencies)
  - Plot the distribution of your data using histograms, boxplots, bar charts
  - Critically reflect any anormalities: Compare your data with the reference literature
  - Are descriptives similar? If not, why so? Try to assess coding problems, different population, unbalanced samples.

### Generate estimates of your investigated effect using regression techniques

- Once you have decided on the type of empirical analyses you would like to perform, run the regressions.
- Perform the regression analyses, that means by using the appropriate procedure to estimate regressions that reflect your empirical strategy.
- Create output tables that report your results which outsiders can understand, for example label your variables properly
- Concentrate on analyzing and interpreting the effects of your variable of interest ($X$)
  - interpret and show in tables ony most important and relevant coefficients related to the research question. For example, you do not need to interpret and display coefficients for all of the incuded control variables, just the main variables of interest. 
- Think about how to interpret your estimates.
- Challenge your approach. Investigate why your estimates could not be plausible?
- Again, compare with existing literature.


- What does your data say? After you run the regressions, look at the results:

    - Are your main coefficients of interest statistically significant, that means is the p-value smaller than 0.05 or any other pre-defined level of significance?
    - Consider also the economic significance of your results. Is the effect you are measuring large or small? 
    - Do your results make sense or are they counterintuitive? This might give you a clue that you might have misspecified your regression or made a mistake in your analysis.


## Resources box

**Data Analysis**


- [Princeton University Library: Getting Started in Data Analysis using Stata and R](https://dss.princeton.edu/training/)
- [Data Analysis for Business, Economics, and Policy](https://gabors-data-analysis.com/)


**Organizing your workflow, programming and automation**

- [Gentzkow M, Shapiro J. Code and Data for the Social Sciences: A Practitionerâ€™s Guide [Internet]. Chicago Booth and NBER; 2014]( https://web.stanford.edu/~gentzkow/research/CodeAndData.pdf)
- [The Stata workflow Guide](https://medium.com/the-stata-guide/the-stata-workflow-guide-52418ce35006)
- [In Stata coding, Style is the Essential: A brief commentary on do-file style](https://michaelshill.net/2015/07/31/in-stata-coding-style-is-the-essential/)



**Data Visualization**

- The chapter [Data Visualization Basics by Hans Sievertsen](https://hhsievertsen.github.io/EconDataBook/data-visualization-basics.html) includes important resources for the fundamentals of data visualization
- [Stata Cheat Sheet on Visualization](https://www.stata.com/bookstore/stata-cheat-sheets/) provides an overview of the technical implementation
- [Jones AM. Data visualization and health econometrics. Foundations and Trends in Econometrics. 2017](https://doi.org/10.1561/0800000033)

**Create journal submission ready output tables**

- [Creating Publication-Quality Tables in Stata](https://ssc.wisc.edu/sscc/pubs/stata_tables.htm)
- [Stata commands to plot regression coefficients, make regression tables and visualize results by Ben Jann](http://repec.sowi.unibe.ch/stata/)



<!--References:

- Fresno State Graduate Writing Studio. [A Statistical Checklist for Your Spring Thesis](https://fresnostategraduatewritingstudio.wordpress.com/)

- https://blog.feedspot.com/data_visualization_blogs/-->


## Example: Hellerstein (1998)

Hellerstein's (1998) study aims to answer the research question if physicians vary their prescription decisions on a patient-by-patient basis or whether they systematically prescribe the same version of a drug, trade-name or generic, to all patients. This means that the secondary data of the CDC (NAMCS and NAMCSd) will be analysed on physician level in a cross-sectional format. This, as we are not looking at the prescription behaviour over time (panel data) but rather if the physicians do or do not prescribe a generic drug.
Over the course of your analysis, you want to explore your dataset, this includes describing and assessing the validity and plausibility. Thus before generating estimates of your investigated effect using regression techniques, you want to describe your data with descriptive statistics tables and, if applicable, figures.
We first reproduce the descriptive statistics of Hellerstein (1998), namely table 1-3 and figure 1-2. Details of created variables can be found in the data preparation .do-file and the notes of the tables and figures in Hellerstein's (1998) paper. Please keep in mind that we used the data of 1991, thus our numbers are not matching with the original paper. 


In the following we explain the steps taken to reproduce table 1-3 and figure 1-2, as well as the reproduction of the empirical analysis. Details and the code can be found in the Appendix <!--[include reference]--> and at the end of the next chapter when reporting the study results.

### Describe your data, assess validity and plausiblity

**Table 1:** Compute the mean and summary statistics for the age and the previously established dummies in the NAMCS data.

**Table 2:** For the first two columns, repeat the procedure of table 1 using the NAMCSd data. For the third column, compute the mean of the generic indicator for all subpopulations defined by the dummies.

**Table 3:** Using summary statistics command, count the number of observations for the full sample and for each of the eight defined drug classes. Further, compute the mean of the generic indicator in the full sample and each drug class subsample. 

**Figure 1:** For each physician, compute the mean of the generic indicator and drop duplicate observations per physician. This way every physician has a unique observation with a respective share of generic prescriptions. To approximate the distribution shown in figure 1, some specifications are not elaborated sufficiently, so we assumed by visual approximation. The assumed specifications are:

  - On what decimal place the generic means were rounded (we chose $.01$)
  - The bandwidth (we chose $0.02$)
  - The kernel function (we chose a bilinear form)

**Figure 2:** Keep physicians that prescribe the same multisource drug to at least six patients, so either in its generic or tradename form. Compute the mean of the generic indicator for each remaining physician and create a dummy variable on whether this mean is zero (i.e. only trade names), one (i.e. only generics), or something in between (i.e. both versions). These three dummies are then plotted in a bar plot. 

### Generate estimates of your investigated effect using regression techniques

Hellerstein applies a random effects probit regression model aggregated on physician level. The parameterization of the model is implemented as follows:

**Dependent variable $Y$**

  - G		*Generic status*
	
**Independent variables $X$**	<!--what about insurance status? That should be X if we follow section 3-->

  - $C$: 	*Drug class (Pain relief omitted, see footnote table 5)*
  - $X$:	*Age, female, Hispanic nonwhite*
  - $P$:	*Medicare, Medicaid, HMO/prepaid, private insurance	(Self-paid omitted)*
  - $S$:	*Specialist*
  - $R$:	*Midwest, South, West (Northeast omitted)*
  - vector $X$, vector $P$:	*Averages across physician*

**Table 4 and 5:**

Estimate the regression coefficients, t-statistics and marginal effects of the regression model. It is not specified whether the model for both tables contain all covariates specified in equation 10 or just the variables mentioned in the tables. We decided to use the full model for both tables. Marginal effects are the average marginal effects (AME) across individuals (footnote table 4).

**Table 6:** Run a separate regression using only observations of a single drug class and report the coefficients of the payment dummies and their AMEs.


Tables 7, 8 and 9 cannot be reproduced due to the missing state identifier in the publicly available data of NACMS.

