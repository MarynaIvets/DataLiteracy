
@article{hellerstein_importance_1998,
	title = {The {Importance} of the {Physician} in the {Generic} versus {Trade}-{Name} {Prescription} {Decision}},
	volume = {29},
	copyright = {Copyright {\textcopyright} 1998 RAND Corporation},
	issn = {0741-6261},
	url = {http://www.jstor.org/stable/2555818},
	doi = {10.2307/2555818},
	abstract = {I examine the importance of physicians in the process by which patients receive either trade-name or generic drugs. Using a dataset on physicians, their patients, and the multisource drugs prescribed, I find that almost all physicians prescribe both types of drugs to their patients, but some physicians are more likely to prescribe generic drugs while other physicians are more likely to prescribe trade-name drugs. Very little of the prescription decision can be explained by observable characteristics of individual patients, but all of the evidence indicates that physicians are indeed an important agent in determining whether patients receive either trade-name or generic drugs.},
	number = {1},
	urldate = {2013-05-14},
	journal = {The RAND Journal of Economics},
	author = {Hellerstein, Judith K.},
	month = apr,
	year = {1998},
	note = {ArticleType: research-article / Full publication date: Spring, 1998 / Copyright {\textcopyright} 1998 RAND Corporation},
	keywords = {TechnologyInnoHealthCare, GenericUtilizationDecomp, DataLiteracy},
	pages = {108--136},
	file = {Hellerstein - 1998 - The Importance of the Physician in the Generic ver.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\TQIMCF46\\Hellerstein - 1998 - The Importance of the Physician in the Generic ver.pdf:application/pdf},
}

@article{danzon_cross-national_2011,
	title = {Cross-{National} {Evidence} on {Generic} {Pharmaceuticals}: {Pharmacy} vs. {Physician}-{Driven} {Markets}},
	shorttitle = {Cross-{National} {Evidence} on {Generic} {Pharmaceuticals}},
	url = {http://www.nber.org/papers/w17226},
	abstract = {This paper examines the role of regulation and competition in generic markets. Generics offer large potential savings to payers and consumers of pharmaceuticals. Whether the potential savings are realized depends on the extent of generic entry and uptake and the level of generic prices. In the U.S., the regulatory, legal and incentive structures encourage prompt entry, aggressive price competition and patient switching to generics. Key features are that pharmacists are authorized and incentivized to switch patients to cheap generics. By contrast, in many other high and middle income countries, generics traditionally competed on brand rather than price because physicians rather than pharmacies are the decision-makers. Physician-driven generic markets tend to have higher generic prices and may have lower generic uptake, depending on regulations and incentives. Using IMS data to analyze generic markets in the U.S., Canada, France, Germany, U.K., Italy, Spain, Japan, Australia, Mexico, Chile, Brazil over the period 1998-2009, we estimate a three-equation model for number of generic entrants, generic prices and generic volume shares. We find little effect of originator defense strategies, significant differences between unbranded and unbranded generics, variation across countries in volume response to prices. Policy changes adopted to stimulate generic uptake and reduce generic prices have been successful in some E.U. countries.},
	urldate = {2013-05-14},
	journal = {NBER Working Paper 17226},
	author = {Danzon, Patricia M. and Furukawa, Michael F.},
	month = jul,
	year = {2011},
	keywords = {DataLiteracy},
	pages = {http://www.nber.org/papers/w17226},
	file = {Danzon und Furukawa - 2011 - Cross-National Evidence on Generic Pharmaceuticals.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\VU485928\\Danzon und Furukawa - 2011 - Cross-National Evidence on Generic Pharmaceuticals.pdf:application/pdf},
}

@article{dunne_review_2013,
	title = {A review of the differences and similarities between generic drugs and their originator counterparts, including economic benefits associated with usage of generic medicines, using {Ireland} as a case study},
	volume = {14},
	issn = {2050-6511},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3579676/},
	doi = {10.1186/2050-6511-14-1},
	abstract = {Generic medicines are those where patent protection has expired, and which may be produced by manufacturers other than the innovator company. Use of generic medicines has been increasing in recent years, primarily as a cost saving measure in healthcare provision. Generic medicines are typically 20 to 90\% cheaper than originator equivalents. Our objective is to provide a high-level description of what generic medicines are and how they differ, at a regulatory and legislative level, from originator medicines. We describe the current and historical regulation of medicines in the world{\textquoteright}s two main pharmaceutical markets, in addition to the similarities, as well as the differences, between generics and their originator equivalents including the reasons for the cost differences seen between originator and generic medicines. Ireland is currently poised to introduce generic substitution and reference pricing. This article refers to this situation as an exemplar of a national system on the cusp of significant health policy change, and specifically details Ireland{\textquoteright}s history with usage of generic medicines and how the proposed changes could affect healthcare provision.},
	urldate = {2013-08-26},
	journal = {BMC Pharmacology \& Toxicology},
	author = {Dunne, Suzanne and Shannon, Bill and Dunne, Colum and Cullen, Walter},
	month = jan,
	year = {2013},
	pmid = {23289757},
	pmcid = {PMC3579676},
	keywords = {DataLiteracy},
	pages = {1},
	file = {Dunne et al_2013_A review of the differences and similarities between generic drugs and their.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\M85X6C5Z\\Dunne et al_2013_A review of the differences and similarities between generic drugs and their.pdf:application/pdf},
}

@article{kesselheim_clinical_2008,
	title = {Clinical {Equivalence} of {Generic} and {Brand}-{Name} {Drugs} {Used} in {Cardiovascular} {Disease}: {A} {Systematic} {Review} and {Meta}-analysis},
	volume = {300},
	issn = {0098-7484},
	shorttitle = {Clinical {Equivalence} of {Generic} and {Brand}-{Name} {Drugs} {Used} in {Cardiovascular} {Disease}},
	url = {http://jama.jamanetwork.com/article.aspx?doi=10.1001/jama.2008.758},
	doi = {10.1001/jama.2008.758},
	language = {en},
	number = {21},
	urldate = {2014-06-13},
	journal = {JAMA},
	author = {Kesselheim, Aaron S.},
	month = dec,
	year = {2008},
	keywords = {DataLiteracy},
	pages = {2514},
}

@book{greenhalgh_how_2014,
	title = {How to {Read} a {Paper}: {The} {Basics} of {Evidence}-{Based} {Medicine}},
	isbn = {978-1-118-80113-0},
	shorttitle = {How to {Read} a {Paper}},
	abstract = {The best-selling introduction to evidence-based medicineIn a clear and engaging style, How to Read a Paper demystifies evidence-based medicine and explains how to critically appraise published research and also put the findings into practice.An ideal introduction to evidence-based medicine, How to Read a Paper explains what to look for in different types of papers and how best to evaluate the literature and then implement the findings in an evidence-based, patient-centred way. Helpful checklist summaries of the key points in each chapter provide a useful framework for applying the principles of evidence-based medicine in everyday practice.This fifth edition has been fully updated with new examples and references to reflect recent developments and current practice. It also includes two new chapters on applying evidence-based medicine with patients and on the common criticisms of evidence-based medicine and responses.How to Read a Paper is a standard text for medical and nursing schools as well as a friendly guide for everyone wanting to teach or learn the basics of evidence-based medicine.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Greenhalgh, Trisha},
	month = feb,
	year = {2014},
	keywords = {DataLiteracy},
	file = {2014_Greenhalgh_.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\28I4R3HL\\2014_Greenhalgh_.pdf:application/pdf},
}

@article{varian_big_2014,
	title = {Big {Data}: {New} {Tricks} for {Econometrics}},
	volume = {28},
	issn = {0895-3309},
	shorttitle = {Big {Data}},
	url = {https://www.aeaweb.org/articles?id=10.1257/jep.28.2.3},
	doi = {10.1257/jep.28.2.3},
	abstract = {Computers are now involved in many economic transactions and can capture data associated with these transactions, which can then be manipulated and analyzed. Conventional statistical and econometric techniques such as regression often work well, but there are issues unique to big datasets that may require different tools. First, the sheer size of the data involved may require more powerful data manipulation tools. Second, we may have more potential predictors than appropriate for estimation, so we need to do some kind of variable selection. Third, large datasets may allow for more flexible relationships than simple linear models. Machine learning techniques such as decision trees, support vector machines, neural nets, deep learning, and so on may allow for more effective ways to model complex relationships. In this essay, I will describe a few of these tools for manipulating and analyzing big data. I believe that these methods have a lot to offer and should be more widely known and used by economists.},
	language = {en},
	number = {2},
	urldate = {2019-06-07},
	journal = {Journal of Economic Perspectives},
	author = {Varian, Hal R.},
	month = may,
	year = {2014},
	keywords = {DataLiteracy},
	pages = {3--28},
	file = {Full Text PDF:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\LRFXYXAG\\Varian - 2014 - Big Data New Tricks for Econometrics.pdf:application/pdf;Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\6YWHX22N\\articles.html:text/html},
}

@article{abadie_econometric_2018,
	title = {Econometric {Methods} for {Program} {Evaluation}},
	volume = {10},
	issn = {1941-1383, 1941-1391},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-economics-080217-053402},
	doi = {10.1146/annurev-economics-080217-053402},
	abstract = {Program evaluation methods are widely applied in economics to assess the effects of policy interventions and other treatments of interest. In this article, we describe the main methodological frameworks of the econometrics of program evaluation. In the process, we delineate some of the directions along which this literature is expanding, discuss recent developments and highlight specific areas where new research may be particularly fruitful.},
	language = {en},
	number = {1},
	urldate = {2019-06-25},
	journal = {Annual Review of Economics},
	author = {Abadie, Alberto and Cattaneo, Matias D.},
	month = aug,
	year = {2018},
	keywords = {DataLiteracy},
	pages = {465--503},
	file = {Abadie und Cattaneo - 2018 - Econometric Methods for Program Evaluation.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\49SUVKB9\\Abadie und Cattaneo - 2018 - Econometric Methods for Program Evaluation.pdf:application/pdf},
}

@article{angrist_credibility_2010,
	title = {The {Credibility} {Revolution} in {Empirical} {Economics}: {How} {Better} {Research} {Design} {Is} {Taking} the {Con} out of {Econometrics}},
	volume = {24},
	issn = {0895-3309},
	shorttitle = {The {Credibility} {Revolution} in {Empirical} {Economics}},
	url = {https://www.aeaweb.org/articles?id=10.1257/jep.24.2.3},
	doi = {10.1257/jep.24.2.3},
	abstract = {Since Edward Leamer's memorable 1983 paper, "Let's Take the Con out of Econometrics," empirical microeconomics has experienced a credibility revolution. While Leamer's suggested remedy, sensitivity analysis, has played a role in this, we argue that the primary engine driving improvement has been a focus on the quality of empirical research designs. The advantages of a good research design are perhaps most easily apparent in research using random assignment. We begin with an overview of Leamer's 1983 critique and his proposed remedies. We then turn to the key factors we see contributing to improved empirical work, including the availability of more and better data, along with advances in theoretical econometric understanding, but especially the fact that research design has moved front and center in much of empirical micro. We offer a brief digression into macroeconomics and industrial organization, where progress -- by our lights -- is less dramatic, although there is work in both fields that we find encouraging. Finally, we discuss the view that the design pendulum has swung too far. Critics of design-driven studies argue that in pursuit of clean and credible research designs, researchers seek good answers instead of good questions. We briefly respond to this concern, which worries us little.},
	language = {en},
	number = {2},
	urldate = {2019-10-08},
	journal = {Journal of Economic Perspectives},
	author = {Angrist, Joshua D. and Pischke, J{\"o}rn-Steffen},
	month = jun,
	year = {2010},
	keywords = {DataLiteracy},
	pages = {3--30},
	file = {Full Text PDF:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\GY9ZIZYN\\Angrist und Pischke - 2010 - The Credibility Revolution in Empirical Economics.pdf:application/pdf;Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\NBBTHFKM\\articles.html:text/html},
}

@article{matthay_alternative_2020,
	title = {Alternative causal inference methods in population health research: {Evaluating} tradeoffs and triangulating evidence},
	volume = {10},
	issn = {2352-8273},
	shorttitle = {Alternative causal inference methods in population health research},
	url = {http://www.sciencedirect.com/science/article/pii/S2352827319301545},
	doi = {10.1016/j.ssmph.2019.100526},
	abstract = {Population health researchers from different fields often address similar substantive questions but rely on different study designs, reflecting their home disciplines. This is especially true in studies involving causal inference, for which semantic and substantive differences inhibit interdisciplinary dialogue and collaboration. In this paper, we group nonrandomized study designs into two categories: those that use confounder-control (such as regression adjustment or propensity score matching) and those that rely on an instrument (such as instrumental variables, regression discontinuity, or differences-in-differences approaches). Using the Shadish, Cook, and Campbell framework for evaluating threats to validity, we contrast the assumptions, strengths, and limitations of these two approaches and illustrate differences with examples from the literature on education and health. Across disciplines, all methods to test a hypothesized causal relationship involve unverifiable assumptions, and rarely is there clear justification for exclusive reliance on one method. Each method entails trade-offs between statistical power, internal validity, measurement quality, and generalizability. The choice between confounder-control and instrument-based methods should be guided by these tradeoffs and consideration of the most important limitations of previous work in the area. Our goals are to foster common understanding of the methods available for causal inference in population health research and the tradeoffs between them; to encourage researchers to objectively evaluate what can be learned from methods outside one's home discipline; and to facilitate the selection of methods that best answer the investigator's scientific questions.},
	language = {en},
	urldate = {2020-05-19},
	journal = {SSM - Population Health},
	author = {Matthay, Ellicott C. and Hagan, Erin and Gottlieb, Laura M. and Tan, May Lynn and Vlahov, David and Adler, Nancy E. and Glymour, M. Maria},
	month = apr,
	year = {2020},
	keywords = {DataLiteracy},
	pages = {100526},
	file = {2020_Matthay et al_SSM - Population Health.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\6685J637\\2020_Matthay et al_SSM - Population Health.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\33A2YFEV\\S2352827319301545.html:text/html},
}

@book{pearl_causality_2009,
	address = {Cambridge},
	title = {Causality},
	isbn = {978-0-521-89560-6},
	url = {https://www.cambridge.org/core/books/causality/B0046844FAE10CBF274D4ACBDAEB5F5B},
	abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. Cited in more than 2,100 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interest to students and professionals in a wide variety of fields. Dr Judea Pearl has received the 2011 Rumelhart Prize for his leading research in Artificial Intelligence (AI) and systems from The Cognitive Science Society.},
	urldate = {2020-06-03},
	publisher = {Cambridge University Press},
	author = {Pearl, Judea},
	year = {2009},
	doi = {10.1017/CBO9780511803161},
	keywords = {DataLiteracy},
	file = {Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\U4642HXR\\B0046844FAE10CBF274D4ACBDAEB5F5B.html:text/html},
}

@book{pearl_causal_2016,
	address = {Chichester, West Sussex},
	title = {Causal inference in statistics: a primer},
	isbn = {978-1-119-18684-7},
	shorttitle = {Causal inference in statistics},
	publisher = {Wiley},
	author = {Pearl, Judea and Glymour, Madelyn and Jewell, Nicholas P.},
	year = {2016},
	keywords = {DataLiteracy},
}

@article{lewbel_identification_2019,
	title = {The {Identification} {Zoo}: {Meanings} of {Identification} in {Econometrics}},
	volume = {57},
	issn = {0022-0515},
	shorttitle = {The {Identification} {Zoo}},
	url = {https://pubs.aeaweb.org/doi/10.1257/jel.20181361},
	doi = {10.1257/jel.20181361},
	abstract = {Over two dozen different terms for identification appear in the econometrics literature, including set identification, causal identification, local identification, generic identification, weak identification, identification at infinity, and many more. This survey: (i) gives a new framework unifying existing definitions of point identification; (ii) summarizes and compares the zooful of different terms associated with identification that appear in the literature; and (iii) discusses concepts closely related to identification, such as normalizations and the differences in identification between structural models and causal, reduced form models. ( JEL C01, C20, C50)},
	language = {en},
	number = {4},
	urldate = {2020-06-25},
	journal = {Journal of Economic Literature},
	author = {Lewbel, Arthur},
	month = dec,
	year = {2019},
	keywords = {DataLiteracy},
	pages = {835--903},
	file = {Lewbel - 2019 - The Identification Zoo Meanings of Identification.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\MM66BBRI\\Lewbel - 2019 - The Identification Zoo Meanings of Identification.pdf:application/pdf},
}

@article{adam_project-management_2019,
	title = {A project-management tool from the tech industry could benefit your lab},
	volume = {573},
	copyright = {2020 Nature},
	url = {https://www.nature.com/articles/d41586-019-02620-6},
	doi = {10.1038/d41586-019-02620-6},
	abstract = {Scientist fans of {\textquoteleft}agile{\textquoteright} and {\textquoteleft}Scrum{\textquoteright} claim that they can help labs to prioritize tasks and cut meeting times {\textemdash} but some research groups are more sceptical.},
	language = {en},
	number = {7772},
	urldate = {2020-08-17},
	journal = {Nature},
	author = {Adam, David},
	month = sep,
	year = {2019},
	note = {Number: 7772
Publisher: Nature Publishing Group},
	keywords = {Scrum, DataLiteracy},
	pages = {151--153},
	file = {2019_Adam_Nature.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\6242E2P9\\2019_Adam_Nature.pdf:application/pdf;Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\D5EB6ZVM\\d41586-019-02620-6.html:text/html},
}

@article{munafo_manifesto_2017,
	title = {A manifesto for reproducible science},
	volume = {1},
	copyright = {2017 Macmillan Publishers Limited},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-016-0021},
	doi = {10.1038/s41562-016-0021},
	abstract = {Improving the reliability and efficiency of scientific research will increase the credibility of the published scientific literature and accelerate discovery. Here we argue for the adoption of measures to optimize key elements of the scientific process: methods, reporting and dissemination, reproducibility, evaluation and incentives. There is some evidence from both simulations and empirical studies supporting the likely effectiveness of these measures, but their broad adoption by researchers, institutions, funders and journals will require iterative evaluation and improvement. We discuss the goals of these measures, and how they can be implemented, in the hope that this will facilitate action toward improving the transparency, reproducibility and efficiency of scientific research.},
	language = {en},
	number = {1},
	urldate = {2020-09-30},
	journal = {Nature Human Behaviour},
	author = {Munaf{\`o}, Marcus R. and Nosek, Brian A. and Bishop, Dorothy V. M. and Button, Katherine S. and Chambers, Christopher D. and Percie du Sert, Nathalie and Simonsohn, Uri and Wagenmakers, Eric-Jan and Ware, Jennifer J. and Ioannidis, John P. A.},
	month = jan,
	year = {2017},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {DataLiteracy},
	pages = {1--9},
	file = {2017_Munaf{\`o} et al_Nature Human Behaviour.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\VCGMW8YW\\2017_Munaf{\`o} et al_Nature Human Behaviour.pdf:application/pdf;Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\74WA47AQ\\s41562-016-0021.html:text/html},
}

@article{tihanyi_thats_2020,
	title = {From {\textquotedblleft}{That}{\textquoteright}s {Interesting}{\textquotedblright} to {\textquotedblleft}{That}{\textquoteright}s {Important}{\textquotedblright}},
	volume = {63},
	issn = {0001-4273, 1948-0989},
	url = {http://journals.aom.org/doi/10.5465/amj.2020.4002},
	doi = {10.5465/amj.2020.4002},
	language = {en},
	number = {2},
	urldate = {2020-12-02},
	journal = {Academy of Management Journal},
	author = {Tihanyi, Laszlo},
	month = apr,
	year = {2020},
	keywords = {DataLiteracy},
	pages = {329--331},
	file = {Tihanyi - 2020 - From {\textquotedblleft}That{\textquoteright}s Interesting{\textquotedblright} to {\textquotedblleft}That{\textquoteright}s Important{\textquotedblright}.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\3XW9HNYI\\Tihanyi - 2020 - From {\textquotedblleft}That{\textquoteright}s Interesting{\textquotedblright} to {\textquotedblleft}That{\textquoteright}s Important{\textquotedblright}.pdf:application/pdf},
}

@book{hall_how_2013,
	address = {Chichester, West Sussex},
	edition = {5th ed},
	title = {How to write a paper},
	isbn = {978-0-470-67220-4},
	abstract = {"This concise paperback is about writing a paper for publication in biomedical journals. Its straightforward format - a chapter covering each of part of the structured abstract - makes it relevant and easy to use for any novice paper writer.How to Write a Paper addresses the mechanics of submission, including electronic submission, and how publishers handle papers, writing letters to journals abstracts for scientific meetings, and assessing papers. This new edition also covers how to write a book review and updated chapters on ethics, electronic publication and submission, and the movement for open access"--Provided by publisher},
	language = {en},
	publisher = {Wiley-Blackwell},
	editor = {Hall, George M.},
	year = {2013},
	note = {OCLC: 828615545},
	keywords = {DataLiteracy},
	file = {Hall - 2013 - How to write a paper.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\SXXN3WFB\\Hall - 2013 - How to write a paper.pdf:application/pdf},
}

@book{pearl_book_2019,
	edition = {1. Edition},
	title = {The {Book} of {Why}: {The} {New} {Science} of {Cause} and {Effect}},
	isbn = {978-0-14-198241-0},
	shorttitle = {The {Book} of {Why}},
	abstract = {The hugely influential book on how the understanding of causality revolutionized science and the world, by the pioneer of artificial intelligence'Wonderful ... illuminating and fun to read' Daniel Kahneman, Nobel Prize-winner and author of Thinking, Fast and Slow'Correlation does not imply causation.' For decades, this mantra was invoked by scientists in order to avoid taking positions as to whether one thing caused another, such as smoking and cancer, or carbon dioxide and global warming. But today, that taboo is dead. The causal revolution, sparked by world-renowned computer scientist Judea Pearl and his colleagues, has cut through a century of confusion and placed cause and effect on a firm scientific basis. Now, Pearl and science journalist Dana Mackenzie explain causal thinking to general readers for the first time, showing how it allows us to explore the world that is and the worlds that could have been. It is the essence of human and artificial intelligence. And just as Pearl's discoveries have enabled machines to think better, The Book of Why explains how we too can think better.'Pearl's accomplishments over the last 30 years have provided the theoretical basis for progress in artificial intelligence and have redefined the term "thinking machine"' Vint Cerf},
	language = {Englisch},
	publisher = {Penguin},
	author = {Pearl, Judea and Mackenzie, Dana},
	month = may,
	year = {2019},
	keywords = {DataLiteracy},
}

@article{george_understanding_2016,
	title = {Understanding and {Tackling} {Societal} {Grand} {Challenges} through {Management} {Research}},
	volume = {59},
	issn = {0001-4273},
	url = {https://journals.aom.org/doi/full/10.5465/amj.2016.4007},
	doi = {10.5465/amj.2016.4007},
	abstract = {{\textquotedblleft}Grand challenges{\textquotedblright} are formulations of global problems that can be plausibly addressed through coordinated and collaborative effort. In this Special Research Forum, we showcase management research that examines societal problems that individuals, organizations, communities, and nations face around the world. We develop a framework to guide future research to provide systematic empirical evidence on the formulation, articulation, and implementation of grand challenges. We highlight several factors that likely enhance or suppress the attainment of collective goals, and identify representative research questions for future empirical work. In so doing, we aspire to encourage management scholars to engage in tackling broader societal challenges through their collaborative research and collective insight.},
	number = {6},
	urldate = {2021-02-24},
	journal = {Academy of Management Journal},
	author = {George, Gerard and Howard-Grenville, Jennifer and Joshi, Aparna and Tihanyi, Laszlo},
	month = sep,
	year = {2016},
	note = {Publisher: Academy of Management},
	keywords = {DataLiteracy},
	pages = {1880--1895},
	file = {2016_George_Howard-Grenville_Joshi_Tihanyi_Academy of Management Journal.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\LMQR3SEA\\2016_George_Howard-Grenville_Joshi_Tihanyi_Academy of Management Journal.pdf:application/pdf;Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\LF98TVYB\\amj.2016.html:text/html},
}

@article{meyer_whats_2017,
	title = {What{\textquoteright}s in a p? {Reassessing} best practices for conducting and reporting hypothesis-testing research},
	volume = {48},
	issn = {1478-6990},
	shorttitle = {What{\textquoteright}s in a p?},
	url = {https://doi.org/10.1057/s41267-017-0078-8},
	doi = {10.1057/s41267-017-0078-8},
	abstract = {Social science research has recently been subject to considerable criticism regarding the validity and power of empirical tests published in leading journals, and business scholarship is no exception. Transparency and replicability of empirical findings are essential to build a cumulative body of scholarly knowledge. Yet current practices are under increased scrutiny to achieve these objectives. JIBS is therefore discussing and revising its editorial practices to enhance the validity of empirical research. In this editorial, we reflect on best practices with respect to conducting, reporting, and discussing the results of quantitative hypothesis-testing research, and we develop guidelines for authors to enhance the rigor of their empirical work. This will not only help readers to assess empirical evidence comprehensively, but also enable subsequent research to build a cumulative body of empirical knowledge.},
	language = {en},
	number = {5},
	urldate = {2021-02-24},
	journal = {Journal of International Business Studies},
	author = {Meyer, Klaus E. and van Witteloostuijn, Arjen and Beugelsdijk, Sjoerd},
	month = jul,
	year = {2017},
	keywords = {DataLiteracy},
	pages = {535--551},
	file = {2017_Meyer_van Witteloostuijn_Beugelsdijk_Journal of International Business Studies.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\IT5GHDM6\\2017_Meyer_van Witteloostuijn_Beugelsdijk_Journal of International Business Studies.pdf:application/pdf},
}

@misc{noauthor_top_nodate,
	title = {Top ten rules of economical writing},
	url = {http://www3.nccu.edu.tw/~jthuang/rules.html},
	urldate = {2021-03-26},
	keywords = {DataLiteracy},
	file = {Top ten rules of economical writing:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\QY6XSPXQ\\rules.html:text/html},
}

@book{mccloskey_economical_2019,
	address = {Chicago ; London},
	edition = {Third Edition},
	title = {Economical {Writing}, {Third} {Edition}: {Thirty}-{Five} {Rules} for {Clear} and {Persuasive} {Prose}},
	isbn = {978-0-226-44807-7},
	shorttitle = {Economical {Writing}, {Third} {Edition}},
	abstract = {Economics is not a field that is known for good writing. Charts, yes. Sparkling prose, no. ~ Except, that is, when it comes to Deirdre Nansen McCloskey. Her conversational and witty yet always clear style is a hallmark of her classic works of economic history, enlivening the dismal science and engaging readers well beyond the discipline. And now she{\textquoteright}s here to share the secrets of how it{\textquoteright}s done. ~Economical Writing is itself economical: a collection of thirty-five pithy rules for making your writing clear, concise, and effective. Proceeding from big-picture ideas to concrete strategies for improvement at the level of the paragraph, sentence, or word, McCloskey shows us that good writing, after all, is not just a matter of taste{\textemdash}it{\textquoteright}s a product of adept intuition and a rigorous revision process. Debunking stale rules, warning us that {\textquotedblleft}footnotes are nests for pedants,{\textquotedblright} and offering an arsenal of readily applicable tools and methods, she shows writers of all levels of experience how to rethink the way they approach their work, and gives them the knowledge to turn mediocre prose into magic. ~ At once efficient and digestible, hilarious and provocative, Economical Writing lives up to its promise. With McCloskey as our guide, it{\textquoteright}s impossible not to see how any piece of writing{\textemdash}on economics or any other subject{\textemdash}can~be~a pleasure to read.},
	language = {Englisch},
	publisher = {University of Chicago Press},
	author = {McCloskey, Deirdre N. and Ziliak, Stephen T.},
	month = may,
	year = {2019},
	keywords = {DataLiteracy},
}

@article{huntingtonklein_influence_2021,
	title = {The influence of hidden researcher decisions in applied microeconomics},
	volume = {59},
	copyright = {{\textcopyright} 2021 Western Economic Association International},
	issn = {1465-7295},
	url = {https://pericles.pericles-prod.literatumonline.com/doi/abs/10.1111/ecin.12992},
	doi = {https://doi.org/10.1111/ecin.12992},
	abstract = {Researchers make hundreds of decisions about data collection, preparation, and analysis in their research. We use a many-analysts approach to measure the extent and impact of these decisions. Two published causal empirical results are replicated by seven replicators each. We find large differences in data preparation and analysis decisions, many of which would not likely be reported in a publication. No two replicators reported the same sample size. Statistical significance varied across replications, and for one of the studies the effect's sign varied as well. The standard deviation of estimates across replications was 3{\textendash}4 times the mean reported standard error.},
	language = {en},
	number = {3},
	urldate = {2021-03-29},
	journal = {Economic Inquiry},
	author = {Huntington-Klein, Nick and Arenas, Andreu and Beam, Emily and Bertoni, Marco and Bloem, Jeffrey R. and Burli, Pralhad and Chen, Naibin and Grieco, Paul and Ekpe, Godwin and Pugatch, Todd and Saavedra, Martin and Stopnitzky, Yaniv},
	month = jul,
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ecin.12992},
	keywords = {DataLiteracy},
	pages = {944--960},
	file = {Huntington-Klein et al_Economic Inquiry.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\5NGUGAVG\\Huntington-Klein et al_Economic Inquiry.pdf:application/pdf;Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\CYXNGH3P\\ecin.html:text/html},
}

@book{angrist_mostly_2008,
	title = {Mostly {Harmless} {Econometrics}},
	isbn = {978-1-4008-2982-8},
	url = {https://www.degruyter.com/document/doi/10.1515/9781400829828/html},
	abstract = {The core methods in today's econometric toolkit are linear regression for statistical control, instrumental variables methods for the analysis of natural experiments, and differences-in-differences methods that exploit policy changes. In the modern experimentalist paradigm, these techniques address clear causal questions such as: Do smaller classes increase learning? Should wife batterers be arrested? How much does education raise wages? Mostly Harmless Econometrics shows how the basic tools of applied econometrics allow the data to speak. In addition to econometric essentials, Mostly Harmless Econometrics covers important new extensions--regression-discontinuity designs and quantile regression--as well as how to get standard errors right. Joshua Angrist and J{\"o}rn-Steffen Pischke explain why fancier econometric techniques are typically unnecessary and even dangerous. The applied econometric methods emphasized in this book are easy to use and relevant for many areas of contemporary social science. An irreverent review of econometric essentials A focus on tools that applied researchers use most Chapters on regression-discontinuity designs, quantile regression, and standard errors Many empirical examples A clear and concise resource with wide applications},
	language = {en},
	urldate = {2021-04-25},
	publisher = {Princeton University Press},
	author = {Angrist, Joshua D. and Pischke, J{\"o}rn-Steffen},
	month = dec,
	year = {2008},
	note = {Publication Title: Mostly Harmless Econometrics},
	keywords = {DataLiteracy},
	file = {Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\3DR23HBH\\html.html:text/html},
}

@article{vilhuber_reproducibility_2020,
	title = {Reproducibility and {Replicability} in {Economics}},
	volume = {2},
	issn = {,},
	url = {https://hdsr.mitpress.mit.edu/pub/fgpmpj1l/release/3},
	doi = {10.1162/99608f92.4f6b9e67},
	abstract = {I provide a summary description of the history and state of reproducibility and replicability in the academic field of economics. I include a discussion of more general replicability and transparency, including the tradition of sharing of research findings and code outside of peer-reviewed publications. I describe the historical context for journals and grey literature in economics, the role of precollected public and nonpublic data, and touch on the role of proprietary software in economics. The increasing importance of restricted-access data environments in economics and the interaction with reproducibility is highlighted. The article concludes with an outlook on current developments, including the role of big data and increased verification of reproducibility in economics.},
	language = {en},
	number = {4},
	urldate = {2021-05-10},
	journal = {Harvard Data Science Review},
	author = {Vilhuber, Lars},
	month = dec,
	year = {2020},
	note = {Publisher: PubPub},
	keywords = {DataLiteracy},
	file = {2020_Vilhuber_Harvard Data Science Review.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\Q9558RFL\\2020_Vilhuber_Harvard Data Science Review.pdf:application/pdf;Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\FB254WUG\\3.html:text/html},
}

@article{orozco_how_2020,
	title = {How to {Make} a {Pie}: {Reproducible} {Research} for {Empirical} {Economics} and {Econometrics}},
	volume = {34},
	copyright = {{\textcopyright} 2020 John Wiley \& Sons Ltd.},
	issn = {1467-6419},
	shorttitle = {How to {Make} a {Pie}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/joes.12389},
	doi = {https://doi.org/10.1111/joes.12389},
	abstract = {Empirical economics and econometrics (EEE) research now relies primarily on the application of code to data sets. Handling the workflow that links data sets, programs, results, and finally manuscript(s) is essential if one wishes to reproduce results. Herein, we highlight the importance of {\textquotedblleft}reproducible research{\textquotedblright} in EEE and propose three simple principles to follow: organize your work, code for others, and automate as much as you can. The first principle, {\textquotedblleft}organize your work{\textquotedblright}, deals with the overall organization of files and the documentation of a research workflow. {\textquotedblleft}Code for others{\textquotedblright} emphasizes that we should take care in how we write code that has to be read by others or later by our future self. Finally, {\textquotedblleft}automate as much as you can{\textquotedblright} is a proposal to avoid any manual treatment and to automate most, if not all, of the steps used in a research process to reduce errors and increase reproducibility. As software is not always the problem and will never be the solution, we illustrate these principles with good habits and tools, with a particular focus on their implementation in most popular software and languages in applied economics.},
	language = {en},
	number = {5},
	urldate = {2021-05-10},
	journal = {Journal of Economic Surveys},
	author = {Orozco, Val{\'e}rie and Bontemps, Christophe and Maign{\'e}, Elise and Piguet, Virginie and Hofstetter, Annie and Lacroix, Anne and Levert, Fabrice and Rousselle, Jean-Marc},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/joes.12389},
	keywords = {DataLiteracy},
	pages = {1134--1169},
	file = {2020_Orozco et al_Journal of Economic Surveys.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\4G79YW78\\Orozco et al. - 2020 - How to Make a Pie Reproducible Research for Empir.pdf:application/pdf;Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\I5UZGUP5\\joes.html:text/html},
}

@techreport{bollen_social_2015,
	title = {Social, behavioral, and economic sciences perspectives on robust and reliable science},
	url = {https://www.nsf.gov/sbe/AC_Materials/SBE_Robust_and_Reliable_Research_Report.pdf},
	institution = {National Science Foundation},
	author = {Bollen, K. and Cacioppo, J. T. and Kaplan, R. M. and Krosnick, J. A.,  and Olds, J. L.},
	year = {2015},
	keywords = {DataLiteracy},
}

@book{bezjak_open_2018,
	title = {Open {Science} {Training} {Handbook}},
	copyright = {Creative Commons Zero - CC0 1.0, Open Access},
	url = {https://zenodo.org/record/1212496},
	abstract = {{\textless}strong{\textgreater}For a readable version of the book, please visit https://book.fosteropenscience.eu{\textless}/strong{\textgreater}

A group of fourteen authors came together in February 2018 at the TIB (German National Library of Science and Technology) in Hannover to create an open, living handbook on Open Science training. High-quality trainings are fundamental when aiming at a cultural change towards the implementation of Open Science principles. Teaching resources provide great support for Open Science instructors and trainers. The Open Science training handbook will be a key resource and a first step towards developing Open Access and Open Science curricula and andragogies. Supporting and connecting an emerging Open Science community that wishes to pass on their knowledge as multipliers, the handbook will enrich training activities and unlock the community{\textquoteright}s full potential.

In this first release of the Open Science Training Handbook, some initial feedback from the community is already included.},
	language = {en},
	urldate = {2021-05-10},
	publisher = {Zenodo},
	author = {Bezjak, Sonja and Clyburne-Sherin, April and Conzett, Philipp and Fernandes, Pedro and G{\"o}r{\"o}gh, Edit and Helbig, Kerstin and Kramer, Bianca and Labastida, Ignasi and Niemeyer, Kyle and Psomopoulos, Fotis and Ross-Hellauer, Tony and Schneider, Ren{\'e} and Tennant, Jon and Verbakel, Ellen and Brinken, Helene and Heller, Lambert},
	month = apr,
	year = {2018},
	doi = {10.5281/ZENODO.1212496},
	keywords = {DataLiteracy},
}

@article{varian_how_2016,
	title = {How to {Build} an {Economic} {Model} in {Your} {Spare} {Time}},
	volume = {61},
	issn = {0569-4345},
	url = {https://doi.org/10.1177/0569434515627089},
	doi = {10.1177/0569434515627089},
	abstract = {Editor{\textquoteright}s Introduction, Originally published in Volume 41, Number 2, Fall 1997, pages 3-10. Hal Varian (born 1947) is widely known by professional economists for his pathbreaking work in the economics of information and networks. Many more know him as the author of two bestselling microeconomics textbooks, one written for undergraduate college students and one designed for advanced graduate students. Through his research and his books, Professor Varian{\textquoteright}s ideas have influenced a generation of economists. In this paper, Professor Varian outlines how he approaches the task of building an economic model to explain an observed phenomena or solve a problem. His words are encouraging advice for graduate students and young economists learning how to {\textquotedblleft}practice the art{\textquotedblright} of economics. Professor Varian offers a number of tips ranging from how to choose a topic, when to read the literature, and even to how to effectively manage your bibliographic citations. Professor Varian{\textquoteright}s advice has passed the market test as this paper remains one of the most referenced and downloaded papers in The American Economist{\textquoteright}s backfile. However, after including the paper on a course reading list several years ago, one doctoral student pointed out to this editor that Professor Varian fails to explain how to find the {\textquotedblleft}spare time{\textquotedblright} that he references in the title!},
	language = {en},
	number = {1},
	urldate = {2021-05-13},
	journal = {The American Economist},
	author = {Varian, Hal R.},
	month = mar,
	year = {2016},
	note = {Publisher: SAGE Publications Inc},
	keywords = {DataLiteracy},
	pages = {81--90},
	file = {2016_Varian_The American Economist.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\MDMDE25P\\2016_Varian_The American Economist.pdf:application/pdf},
}

@techreport{pischke_how_2012,
	title = {How to get started on research in economics?},
	url = {http://econ.lse.ac.uk/staff/spischke/phds/get_started.pdf},
	author = {Pischke, Steve},
	year = {2012},
	keywords = {DataLiteracy},
}

@misc{trochim_problem_nodate,
	title = {Problem {Formulation}},
	url = {https://conjointly.com/kb/problem-formulation/},
	abstract = {Probably one of the most common sources of research ideas is the experience of practical problems in the field.},
	language = {en},
	urldate = {2021-05-13},
	author = {Trochim, William},
	keywords = {DataLiteracy},
	file = {Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\JS4XLF4N\\problem-formulation.html:text/html},
}

@misc{schilbach_5_2019,
	address = {MIT 14.192 guest lecture},
	title = {5 steps toward a paper},
	url = {https://www.dropbox.com/s/q7wjaidl5w91srt/Guest%20lecture%20FS.pdf?dl=0},
	language = {de},
	urldate = {2021-05-13},
	author = {Schilbach, Frank},
	month = nov,
	year = {2019},
	keywords = {DataLiteracy},
	file = {Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\CASIMFBI\\Guest lecture FS.html:text/html},
}

@misc{noauthor_how_2019,
	title = {How to {Write} a {Strong} {Hypothesis} {\textbar} {Steps} and {Examples}},
	url = {https://www.scribbr.com/research-process/hypotheses/},
	abstract = {A hypothesis is a statement that can be tested by scientific research. It usually predicts a relationship between two or more variables.},
	language = {en-US},
	urldate = {2021-05-13},
	journal = {Scribbr},
	month = apr,
	year = {2019},
	keywords = {DataLiteracy},
	file = {Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\GUDNN85F\\hypotheses.html:text/html},
}

@misc{noauthor_developing_2019,
	title = {Developing {Strong} {Research} {Questions} {\textbar} {Criteria} and {Examples}},
	url = {https://www.scribbr.com/research-process/research-questions/},
	abstract = {Research questions give your project a clear focus. They should be specific and feasible, but complex enough to merit a detailed answer.},
	language = {en-US},
	urldate = {2021-05-13},
	journal = {Scribbr},
	month = apr,
	year = {2019},
	keywords = {DataLiteracy},
	file = {Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\QGTEJ5WT\\research-questions.html:text/html},
}

@article{jones_data_2017,
	title = {Data visualization and health econometrics},
	url = {https://doi.org/10.1561/0800000033},
	language = {en},
	urldate = {2021-09-13},
	journal = {Foundations and Trends in Econometrics},
	author = {Jones, Andrew Michael},
	month = aug,
	year = {2017},
	note = {Publisher: York},
	keywords = {DataLiteracy},
	file = {2017_Jones_Foundations and Trends in Econometrics.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\ILZKED4Q\\2017_Jones_Foundations and Trends in Econometrics.pdf:application/pdf;Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\8TE4MDQK\\120147.html:text/html},
}

@article{lawton_effective_2019,
	title = {Effective use of secondary quantitative data sources},
	url = {https://www.elgaronline.com/view/edcoll/9781788118767/9781788118767.00020.xml},
	abstract = {{\textless}p{\textgreater}This chapter reflects on the effective use of secondary data sources to investigate the quality of work. Case studies of policy-orientated research illustrate the strengths and weaknesses of some of the secondary data available in the UK that pertain to the structure of employment, population and business demographics, income and earnings, and exclusion from the labour market. The case studies introduce the reader to the role of the Office for National Statistics and the principles affecting the collection, dissemination and interpretation of sample surveys and management information, in order to demonstrate that relatively simple descriptive analysis, if underpinned by a deep understanding of the data sources, can lead to observations that are of great value to decision makers.{\textless}/p{\textgreater}},
	language = {en\_US},
	urldate = {2021-09-13},
	journal = {Handbook of Research Methods on the Quality of Working Lives},
	author = {Lawton, Chris},
	month = sep,
	year = {2019},
	note = {ISBN: 9781788118774
Publisher: Edward Elgar Publishing
Section: Handbook of Research Methods on the Quality of Working Lives},
	keywords = {DataLiteracy},
	file = {2019_Lawton_Handbook of Research Methods on the Quality of Working Lives.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\NKDH9IV9\\2019_Lawton_Handbook of Research Methods on the Quality of Working Lives.pdf:application/pdf;Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\MRHJ9HGG\\9781788118767.00020.html:text/html},
}

@incollection{hair_nature_2019,
	edition = {4},
	title = {The {Nature} and {Sources} of {Secondary} {Business} {Data}},
	isbn = {978-0-429-20337-4},
	abstract = {The nature and scope of secondary data in business research is described. Advantages and disadvantages of secondary data are summarized. Sources of secondary data, particularly digital data, are identified as well as how to evaluate the validity and reliability of the sources.},
	booktitle = {Essentials of {Business} {Research} {Methods}},
	publisher = {Routledge},
	author = {Hair, Joe F. and Page, Michael and Brunsveld, Niek},
	year = {2019},
	note = {Num Pages: 27},
	keywords = {DataLiteracy},
	file = {2019_Hair_Page_Brunsveld_Essentials of Business Research Methods.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\NINRT3RL\\2019_Hair_Page_Brunsveld_Essentials of Business Research Methods.pdf:application/pdf},
}

@incollection{fitchett_quantitative_2017,
	title = {Quantitative {Research} and {Large}-{Scale} {Secondary} {Analysis} in {Social} {Studies}},
	isbn = {978-1-118-76874-7},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118768747.ch4},
	abstract = {This chapter describes how quantitative research can and should be used to expand the types of research questions examined in social studies. The authors offer a framework for future researchers to consider when conducting quantitative research. They also applied the framework to a review of quantitative and mixed-method research articles from 2003 to 2014 in three major research journals of the field. Exemplars from their findings are provided to guide future studies. Lastly, this chapter focuses specifically on the potential of secondary data analysis for researchers interested in quantitative research.},
	language = {en},
	urldate = {2021-09-13},
	booktitle = {The {Wiley} {Handbook} of {Social} {Studies} {Research}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Fitchett, Paul G. and Heafner, Tina L.},
	year = {2017},
	doi = {10.1002/9781118768747.ch4},
	note = {Section: 4
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118768747.ch4},
	keywords = {DataLiteracy},
	pages = {68--94},
	file = {2017_Fitchett_Heafner_The Wiley Handbook of Social Studies Research.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\D7LH8KUZ\\2017_Fitchett_Heafner_The Wiley Handbook of Social Studies Research.pdf:application/pdf;Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\ZR6GCCZH\\9781118768747.html:text/html},
}

@incollection{eriksson_secondary_2016,
	title = {Secondary data sources for drug utilization research},
	isbn = {978-1-118-94974-0},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118949740.ch4},
	abstract = {Data useful for drug utilization studies are routinely gathered for administrative purposes and as part of patient care. Drug utilization researchers can answer a wide range of questions using secondary analyses of aggregate- and individual-level drug utilization data. Aggregate-level data, such as sales data, can be used to describe and forecast drug utilization and expenditure and to evaluate the impact of pharmaceutical policies and interventions. Cross-national comparisons of drug utilization and ecological studies can be performed based on analyses of aggregate-level data. Secondary analyses of individual-level data, including electronic health records, pharmacy dispensing and reimbursement databases, as well as patient registries and population health survey data, are performed frequently in drug utilization research. Individual-level data can be used to estimate the incidence, prevalence and duration of drug use and to follow drug utilization patterns over time. Linking records from different data sources allows a more comprehensive patient and prescriber profile to be built, enabling researchers to study the appropriateness of drug use and factors potentially influencing drug utilization. Record linkage can also help complete drug exposure histories across different health care settings. Data quality is of importance in database analyses of drug utilization. Before conducting analyses of secondary data, the drug utilization researcher should obtain a thorough knowledge of the unique characteristics of the data source and weigh the strengths and limitations of its use in answering the research questions of interest.},
	language = {en},
	urldate = {2021-09-16},
	booktitle = {Drug {Utilization} {Research}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Eriksson, Irene and Ib{\'a}{\~n}ez, Luisa},
	year = {2016},
	doi = {10.1002/9781118949740.ch4},
	note = {Section: 4
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118949740.ch4},
	keywords = {DataLiteracy},
	pages = {39--48},
	file = {Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\E2GPAPKE\\9781118949740.html:text/html},
}

@article{huschka_why_2013,
	title = {Why {Should} {We} {Share} {Our} {Data}, {How} {Can} it {Be} {Organized}, and {What} are the {Challenges} {Ahead}?},
	issn = {1556-5068},
	url = {http://www.ssrn.com/abstract=2272028},
	doi = {10.2139/ssrn.2272028},
	abstract = {The paper is based on a keynote talk held at the international conference {\textquotedblleft}Opening data services in the social sciences{\textquotedblright}, Belgrade, Serbia, 20/21 March 2013. The author wishes to thank the SERSCIDA project1.},
	language = {en},
	urldate = {2021-09-19},
	journal = {SSRN Electronic Journal},
	author = {Huschka, Denis},
	year = {2013},
	keywords = {DataLiteracy},
	file = {Huschka - 2013 - Why Should We Share Our Data, How Can it Be Organi.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\F2IL7VVF\\Huschka - 2013 - Why Should We Share Our Data, How Can it Be Organi.pdf:application/pdf},
}

@article{pirro_how_2019,
	title = {How agile project management can work for your research},
	copyright = {2021 Nature},
	url = {https://www.nature.com/articles/d41586-019-01184-9},
	doi = {10.1038/d41586-019-01184-9},
	abstract = {Laura Pirro outlines an approach that could increase output and improve motivation.},
	language = {en},
	urldate = {2022-02-22},
	journal = {Nature},
	author = {Pirro, Laura},
	month = apr,
	year = {2019},
	note = {00013 
Bandiera\_abtest: a
Cg\_type: Career Column
Publisher: Nature Publishing Group
Subject\_term: Research management, Careers, Education},
	keywords = {DataLiteracy},
	file = {Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\LWLYS8R7\\d41586-019-01184-9.html:text/html},
}

@article{santiago-lopez_six_2019,
	title = {Six project-management tips for your {PhD}},
	volume = {573},
	copyright = {2021 Nature},
	url = {https://www.nature.com/articles/d41586-018-07860-6},
	doi = {10.1038/d41586-018-07860-6},
	abstract = {Use strategies from the private sector to better manage your graduate project.},
	language = {en},
	number = {7772},
	urldate = {2022-02-22},
	journal = {Nature},
	author = {Santiago-Lopez, Angel},
	month = jan,
	year = {2019},
	note = {00001 
Bandiera\_abtest: a
Cg\_type: Career Column
Number: 7772
Publisher: Nature Publishing Group
Subject\_term: Careers, Lab life},
	keywords = {DataLiteracy},
	pages = {153--153},
	file = {2019_Santiago-Lopez_Nature.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\E42RHA2K\\2019_Santiago-Lopez_Nature.pdf:application/pdf;Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\63FG4BFZ\\d41586-018-07860-6.html:text/html},
}

@article{plamen_writing_2020,
	title = {Writing {Tips} for {Economics} {Research} {Papers}},
	url = {https://mpra.ub.uni-muenchen.de/105088/},
	number = {No. 105088},
	journal = {MPRA Paper},
	author = {Plamen, Nikolov},
	year = {2020},
	note = {00000},
	keywords = {DataLiteracy},
	file = {Plamen_MPRA Paper.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\V97LSMBM\\Plamen_MPRA Paper.pdf:application/pdf},
}

@article{cochrane_writing_2005,
	title = {Writing {Tips} for {Ph}. {D}. {Students}},
	url = {http://gsbwww.uchicago.edu/fac/john.cochrane/research/Papers/},
	language = {en},
	author = {Cochrane, John H},
	month = jun,
	year = {2005},
	note = {00042},
	keywords = {DataLiteracy},
	pages = {13},
	file = {Cochrane - Writing Tips for Ph. D. Students.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\EKNMKJNY\\Cochrane - Writing Tips for Ph. D. Students.pdf:application/pdf},
}

@book{dudenhefer_guide_2014,
	address = {Duke University},
	title = {Guide to {Writing} in {Economics}},
	author = {Dudenhefer, Paul},
	month = mar,
	year = {2014},
	note = {00021},
	keywords = {DataLiteracy},
	file = {Dudenhefer, Paul - Guide to Writing in Economics.pdf:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\FLB6BNTW\\Dudenhefer, Paul - Guide to Writing in Economics.pdf:application/pdf},
}

@book{huntington-klein_chapter_nodate,
	title = {Chapter 16 - {Fixed} {Effects} {\textbar} {The} {Effect}},
	url = {https://theeffectbook.net/ch-FixedEffects.html},
	abstract = {Chapter 16 - Fixed Effects {\textbar} The Effect is a textbook that covers the basics and concepts of research design, especially as applied to causal inference from observational data.},
	urldate = {2022-03-01},
	author = {Huntington-Klein, Nick},
	note = {00000},
	keywords = {DataLiteracy},
	file = {Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\SA4DCBEG\\ch-FixedEffects.html:text/html},
}

@book{cameron_microeconometrics_2005,
	address = {Cambridge},
	edition = {Nachdr.},
	title = {Microeconometrics: methods and applications},
	isbn = {978-0-521-84805-3},
	shorttitle = {Microeconometrics},
	language = {eng},
	publisher = {Cambridge Univ. Press},
	author = {Cameron, Adrian Colin and Trivedi, Pravin K.},
	year = {2005},
	note = {12813},
	keywords = {DataLiteracy},
}

@misc{statista_prescription_nodate,
	title = {Prescription drug spending in {U}.{S}. 1960-2020},
	url = {https://www.statista.com/statistics/184914/prescription-drug-expenditures-in-the-us-since-1960/},
	abstract = {Spending on prescription drugs in the U.S. was forecast to reach 360 billion U.S. dollars in 2020, around 105 billion U.S. dollars more than in 2010.},
	language = {en},
	urldate = {2022-03-01},
	journal = {Statista},
	author = {Statista},
	note = {00000},
	keywords = {DataLiteracy},
	file = {Snapshot:C\:\\Users\\KFischer\\Documents\\Zotero\\storage\\PF4RKAQ3\\prescription-drug-expenditures-in-the-us-since-1960.html:text/html},
}

@article{dranove_medicaid_1989,
	title = {Medicaid {Drug} {Formulary} {Restrictions}},
	volume = {32},
	issn = {0022-2186},
	url = {https://www.journals.uchicago.edu/doi/10.1086/467172},
	doi = {10.1086/467172},
	number = {1},
	urldate = {2022-03-01},
	journal = {The Journal of Law and Economics},
	author = {Dranove, David},
	month = apr,
	year = {1989},
	note = {00075 
Publisher: The University of Chicago Press},
	keywords = {DataLiteracy},
	pages = {143--162},
}
